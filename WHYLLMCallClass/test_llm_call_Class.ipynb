{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchainLLMæ¨¡æ¿\n",
    "from typing import Any, Dict, Iterator, List, Mapping, Optional\n",
    "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from langchain_core.outputs import GenerationChunk\n",
    "\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    \"\"\"A custom chat model that echoes the first `n` characters of the input.\n",
    "\n",
    "    When contributing an implementation to LangChain, carefully document\n",
    "    the model including the initialization parameters, include\n",
    "    an example of how to initialize the model and include any relevant\n",
    "    links to the underlying models documentation or API.\n",
    "\n",
    "    Example:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            model = CustomChatModel(n=2)\n",
    "            result = model.invoke([HumanMessage(content=\"hello\")])\n",
    "            result = model.batch([[HumanMessage(content=\"hello\")],\n",
    "                                 [HumanMessage(content=\"world\")]])\n",
    "    \"\"\"\n",
    "\n",
    "    n: int\n",
    "    \"\"\"The number of characters from the last message of the prompt to be echoed.\"\"\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        \"\"\"Run the LLM on the given input.\n",
    "\n",
    "        Override this method to implement the LLM logic.\n",
    "\n",
    "        Args:\n",
    "            prompt: The prompt to generate from.\n",
    "            stop: Stop words to use when generating. Model output is cut off at the\n",
    "                first occurrence of any of the stop substrings.\n",
    "                If stop tokens are not supported consider raising NotImplementedError.\n",
    "            run_manager: Callback manager for the run.\n",
    "            **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
    "                to the model provider API call.\n",
    "\n",
    "        Returns:\n",
    "            The model output as a string. Actual completions SHOULD NOT include the prompt.\n",
    "        \"\"\"\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        return prompt[: self.n]\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[GenerationChunk]:\n",
    "        \"\"\"Stream the LLM on the given prompt.\n",
    "\n",
    "        This method should be overridden by subclasses that support streaming.\n",
    "\n",
    "        If not implemented, the default behavior of calls to stream will be to\n",
    "        fallback to the non-streaming version of the model and return\n",
    "        the output as a single chunk.\n",
    "\n",
    "        Args:\n",
    "            prompt: The prompt to generate from.\n",
    "            stop: Stop words to use when generating. Model output is cut off at the\n",
    "                first occurrence of any of these substrings.\n",
    "            run_manager: Callback manager for the run.\n",
    "            **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
    "                to the model provider API call.\n",
    "\n",
    "        Returns:\n",
    "            An iterator of GenerationChunks.\n",
    "        \"\"\"\n",
    "        for char in prompt[: self.n]:\n",
    "            chunk = GenerationChunk(text=char)\n",
    "            if run_manager:\n",
    "                run_manager.on_llm_new_token(chunk.text, chunk=chunk)\n",
    "\n",
    "            yield chunk\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return a dictionary of identifying parameters.\"\"\"\n",
    "        return {\n",
    "            # The model name allows users to specify custom token counting\n",
    "            # rules in LLM monitoring applications (e.g., in LangSmith users\n",
    "            # can provide per token pricing for their model and monitor\n",
    "            # costs for the given LLM.)\n",
    "            \"model_name\": \"CustomChatModel\",\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Get the type of language model used by this chat model. Used for logging purposes only.\"\"\"\n",
    "        return \"custom\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æˆ‘çš„LLMæ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Mapping\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from typing import Dict, Any\n",
    "from pydantic import Field\n",
    "class CustomLLM(LLM):\n",
    "    \"\"\"è‡ªå®šä¹‰è¯­è¨€æ¨¡å‹ç±»ï¼Œç»§æ‰¿è‡ªLLMåŸºç±»ã€‚\n",
    "\n",
    "    å±æ€§:\n",
    "        model_name: æ¨¡å‹åç§°ã€‚\n",
    "        url: æ¨¡å‹å¹³å°çš„URLï¼Œéœ€è¦å…ˆå»æŸä¸ªurlè·å¾—access_token,ç„¶åå†å»å¦ä¸€ä¸ªurlè·å¾—æ¨¡å‹çš„ç»“æœã€‚ï¼ˆå¯é€‰ï¼‰\n",
    "        api_key: APIå¯†é’¥ã€‚ï¼ˆå¯é€‰ï¼‰\n",
    "        appid: åº”ç”¨IDã€‚ï¼ˆå¯é€‰ï¼‰\n",
    "        api_secret: APIå¯†ç ã€‚ï¼ˆå¯é€‰ï¼‰\n",
    "        access_token: æ¨¡å‹å¹³å°çš„è®¿é—®ä»¤ç‰Œã€‚ï¼ˆå¯é€‰ï¼‰\n",
    "        timeout: æ¨¡å‹å¹³å°çš„è¶…æ—¶æ—¶é—´ã€‚\n",
    "        temperature: æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§çš„å‚æ•°ï¼Œå€¼è¶Šå¤§ï¼Œè¾“å‡ºçš„éšæœºæ€§è¶Šå¤§ã€‚\n",
    "        model_kwargs: æ¨¡å‹çš„å…¶ä»–å¯é€‰å‚æ•°ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    url: str = None\n",
    "\n",
    "    api_key: str = None\n",
    "\n",
    "    appid: str = None\n",
    "\n",
    "    api_secret: str = None\n",
    "\n",
    "    access_token: str = None\n",
    "\n",
    "    request_timeout: float = 50.0\n",
    "\n",
    "    temperature: float = 0.36\n",
    "\n",
    "    # # å¿…å¤‡çš„å¯é€‰å‚æ•°\n",
    "    # model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    # å®šä¹‰ä¸€ä¸ªè¿”å›é»˜è®¤å‚æ•°çš„æ–¹æ³•\n",
    "    @property\n",
    "    def _default_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–è°ƒç”¨é»˜è®¤å‚æ•°ã€‚\"\"\"\n",
    "        normal_params = {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"request_timeout\": self.request_timeout,\n",
    "            }\n",
    "        return {**normal_params}\n",
    "    \n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {**{\"model_name\": self.model_name}, **self._default_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åƒå¸†å¹³å°è‡ªå®šä¹‰LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼æˆ‘æ˜¯é›¶ä¸€ä¸‡ç‰©å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘å« Yiï¼Œæˆ‘æ˜¯ç”±é›¶ä¸€ä¸‡ç‰©çš„ä¼˜ç§€å·¥ç¨‹å¸ˆä»¬ä¸€èµ·å¼€å‘çš„ã€‚æˆ‘å¯ä»¥å›ç­”ä½ çš„é—®é¢˜ï¼Œæä¾›ä¿¡æ¯ï¼Œå¸®åŠ©ä½ è§£å†³é—®é¢˜ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# å‘æˆæƒæœåŠ¡åœ°å€ https://aip.baidubce.com/oauth/2.0/token å‘é€è¯·æ±‚ï¼ˆæ¨èä½¿ç”¨POSTï¼‰ã€‚\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import Dict, List, Optional, Any\n",
    "from test_MYLLM import CustomLLM\n",
    "from pydantic import Field\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "def get_access_token(API_KEY: str, SECRET_KEY: str):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ AKï¼ŒSK ç”Ÿæˆé‰´æƒç­¾åï¼ˆAccess Tokenï¼‰\n",
    "    :return: access_tokenï¼Œæˆ–æ˜¯None(å¦‚æœé”™è¯¯)\n",
    "    \"\"\"\n",
    "    url = \"https://aip.baidubce.com/oauth/2.0/token\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    params = {\"grant_type\": \"client_credentials\", \"client_id\": API_KEY, \"client_secret\": SECRET_KEY}\n",
    "    return str(requests.post(url, params=params).json().get(\"access_token\"))\n",
    "\n",
    "class QianFanLLM(CustomLLM):\n",
    "    model_name: str = None\n",
    "    \"\"\"\n",
    "    model_name: å¯é€‰æ‹©\n",
    "    - \n",
    "    \"\"\"\n",
    "    url: str = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/yi_34b_chat?access_token={}\"\n",
    "    api_key: str = None\n",
    "    appid: str = None\n",
    "    api_secret: str = None\n",
    "    access_token: str = None\n",
    "    request_timeout: float = 50.0\n",
    "    # model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "    def init_access_token(self):\n",
    "        # å½“æ¨¡å‹åˆå§‹åŒ–æ—¶ï¼Œè·å–access_token\n",
    "        # åŒæ—¶éœ€è¦æœ‰api_keyå’Œapi_secret\n",
    "        if self.api_key is None or self.api_secret is None:\n",
    "            raise ValueError(\"api_key and api_secret are required.\")\n",
    "        else:\n",
    "            try:\n",
    "                self.access_token = get_access_token(self.api_key, self.api_secret)\n",
    "                # print(\"access_token: \", self.access_token)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸\n",
    "    \n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        # è°ƒç”¨æ¨¡å‹çš„é€»è¾‘\n",
    "        if self.access_token is None:\n",
    "            self.init_access_token()\n",
    "        # å‘é€è¯·æ±‚åˆ°apiè°ƒç”¨çš„url\n",
    "        url = self.url.format(self.access_token)\n",
    "\n",
    "        # é…ç½®POSTå‚æ•°\n",
    "        payload = json.dumps({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \n",
    "                    \"content\": prompt}\n",
    "                    ],\n",
    "                'temperature': self.temperature\n",
    "        })\n",
    "\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "        response = requests.request(\"POST\", url, headers=headers, data=payload, timeout=self.request_timeout)\n",
    "        # è¿”å›ç»“æœ\n",
    "        # print(response)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(\"Request failed with status code: {}\".format(response.status_code))\n",
    "        else:\n",
    "            # è¿”å›çš„æ˜¯ä¸€ä¸ª Json å­—ç¬¦ä¸²\n",
    "            text = json.loads(response.text)\n",
    "            # print(js)\n",
    "            return text[\"result\"]\n",
    "        \n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            **{\"model\": self.model_name},\n",
    "            **super()._identifying_params,\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"QianFanLLM\"\n",
    "            \n",
    "\n",
    "# æµ‹è¯•QianFanLLM\n",
    "model = QianFanLLM(model_name=\"Yi-34B-Chat\", \n",
    "                   api_key=\"HnngI6IOybeRJyLgvtowIRUt\", \n",
    "                   api_secret=\"Vx7tFMIdGDrouCsyBRuChmbNBHhlMM2e\")\n",
    "result = model.invoke(\"ä½ å¥½\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*åƒå¸†æµ‹è¯•æˆåŠŸ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions_pro?access_token=\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions_pro_preemptible?access_token=\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/eb-instant?access_token={}\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/yi_34b_chat?access_token=\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions?access_token=\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/eb-instant?access_token={access_token}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ™ºè°±LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹æ™ºè°±æ¸…è¨€ï¼ˆChatGLMï¼‰ï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import Dict, List, Optional, Any\n",
    "from test_MYLLM import CustomLLM\n",
    "import zhipuai\n",
    "from langchain.pydantic_v1 import Field, root_validator\n",
    "from langchain.utils import get_from_dict_or_env\n",
    "from zhipuai import ZhipuAI\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "class ZhiPuLLM(CustomLLM):\n",
    "    url: str = \"https://open.bigmodel.cn/api/paas/v4/chat/completions\"\n",
    "    model_name: str = None\n",
    "    api_key: str = None\n",
    "    appid: str = None\n",
    "    api_secret: str = None\n",
    "    access_token: str = None\n",
    "    client: Any\n",
    "    request_timeout: float = 50.0\n",
    "    temperature: float = 0.36\n",
    "    model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    # éªŒè¯zhipu_api_key\n",
    "    @root_validator\n",
    "    def validate_api_key(cls, values: Dict) -> Dict:\n",
    "        values[\"ZHIPUAI_API_KEY\"] = get_from_dict_or_env(values,\"zhipuai_api_key\", \"ZHIPUAI_API_KEY\")\n",
    "\n",
    "        try:\n",
    "            zhipuai.api_key = values[\"ZHIPUAI_API_KEY\"]\n",
    "            # print(zhipuai.api_key)\n",
    "            values[\"client\"] = ZhipuAI(api_key=zhipuai.api_key)\n",
    "            # print(values[\"client\"])\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"api_key is required.\")\n",
    "\n",
    "        return values\n",
    "    \n",
    "\n",
    "\n",
    "    @property\n",
    "    def _default_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get the default parameters.\"\"\"\n",
    "        normal_params = {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"request_timeout\": self.request_timeout,\n",
    "            \"model\": self.model_name,\n",
    "        }\n",
    "        return {**normal_params, **self.model_kwargs}\n",
    "\n",
    "\n",
    "    def _convert_prompt_msg_params(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        **kwargs: Any,\n",
    "    ) -> dict:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        return {\n",
    "            **{\"model\": self.model_name, \"messages\": messages},\n",
    "            **kwargs,\n",
    "        }\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:     \n",
    "\n",
    "                # é…ç½®POSTå‚æ•°\n",
    "        payload = json.dumps({\n",
    "\n",
    "            \"model\": self.model_name,\n",
    "\n",
    "            \"messages\": [\n",
    "                    {\"role\": \"user\", \n",
    "                    \"content\": prompt}\n",
    "                    ],\n",
    "                'temperature': self.temperature\n",
    "        })\n",
    "\n",
    "\n",
    "        headers = {\n",
    "            'Authorization': 'Bearer ' + self.api_key,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "               }\n",
    "\n",
    "        response = requests.request(\"POST\", self.url, headers=headers, data=payload, timeout=self.request_timeout)\n",
    "        # print(response)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(\"Request failed with status code: {}\".format(response.status_code))\n",
    "        else:\n",
    "            # è¿”å›çš„æ˜¯ä¸€ä¸ª Json å­—ç¬¦ä¸²\n",
    "            text = json.loads(response.text)\n",
    "            return text[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "\n",
    "        # return response.choices[0].message.content\n",
    "            \n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            **super()._identifying_params,\n",
    "        }\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return type of llm.\"\"\"\n",
    "        return \"ZhiPuLLM\"\n",
    "\n",
    "# æµ‹è¯•ZhiPuLLM\n",
    "model = ZhiPuLLM(model_name = \"glm-3-turbo\",\n",
    "                  api_key = \"26128e545ddd8a44c6588c4d530a5fbe.hj6klSWNSFWnli9p\",\n",
    "                  )\n",
    "\n",
    "print(model.invoke(\"ä½ å¥½\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*æ™ºè°±æµ‹è¯•æˆåŠŸ*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ˜Ÿç«spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½\n",
      "### error: Handshake status 401 Unauthorized -+-+- {'date': 'Thu, 25 Apr 2024 13:56:06 GMT', 'content-type': 'application/json; charset=utf-8', 'connection': 'keep-alive', 'content-length': '76', 'server': 'kong/1.3.0'} -+-+- b'{\"message\":\"HMAC signature cannot be verified: fail to retrieve credential\"}'\n",
      "### error: on_close() takes 1 positional argument but 3 were given\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import _thread as thread\n",
    "import os\n",
    "import queue\n",
    "import time\n",
    "import base64\n",
    "\n",
    "import base64\n",
    "import datetime\n",
    "import hashlib\n",
    "import hmac\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import ssl\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from urllib.parse import urlencode\n",
    "from wsgiref.handlers import format_date_time\n",
    "\n",
    "import websocket\n",
    "# import openpyxl\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "from test_MYLLM import CustomLLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "\n",
    "class Spark_LLM(CustomLLM):\n",
    "    # è®¯é£æ˜Ÿç«å¤§æ¨¡å‹çš„è‡ªå®šä¹‰ LLM\n",
    "    # URL\n",
    "    url : str = \"wss://spark-api.xf-yun.com/v3.5/chat\"\n",
    "    # APPID\n",
    "    appid : str = None\n",
    "    # APISecret\n",
    "    api_secret : str = None\n",
    "    # Domain\n",
    "    domain :str = \"generalv3.5\"\n",
    "    # max_token\n",
    "    max_tokens : int = 4096\n",
    "\n",
    "    def getText(self, role, content, text = []):\n",
    "        # role æ˜¯æŒ‡å®šè§’è‰²ï¼Œcontent æ˜¯ prompt å†…å®¹\n",
    "        jsoncon = {}\n",
    "        jsoncon[\"role\"] = role\n",
    "        jsoncon[\"content\"] = content\n",
    "        text.append(jsoncon)\n",
    "        print(text)\n",
    "        return text\n",
    "\n",
    "    def _call(self, \n",
    "              prompt : str, \n",
    "              stop: Optional[List[str]] = None,\n",
    "              run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "              **kwargs: Any):\n",
    "        if self.api_key == None or self.appid == None or self.api_secret == None:\n",
    "            # ä¸‰ä¸ª Key å‡å­˜åœ¨æ‰å¯ä»¥æ­£å¸¸è°ƒç”¨\n",
    "            print(\"è¯·å¡«å…¥ Key\")\n",
    "            raise ValueError(\"Key ä¸å­˜åœ¨\")\n",
    "        # å°† Prompt å¡«å……åˆ°æ˜Ÿç«æ ¼å¼\n",
    "        question = prompt\n",
    "        print(question)\n",
    "        # å‘èµ·è¯·æ±‚\n",
    "        try:\n",
    "            response = main(self.appid, self.api_key, self.api_secret, self.url, self.domain, question)\n",
    "            # print(response)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"è¯·æ±‚å¤±è´¥\")\n",
    "            return \"è¯·æ±‚å¤±è´¥\"\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"Spark\"\n",
    "\n",
    "\n",
    "class Ws_Param(object):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self, APPID, APIKey, APISecret, gpt_url):\n",
    "        self.APPID = APPID\n",
    "        self.APIKey = APIKey\n",
    "        self.APISecret = APISecret\n",
    "        self.host = urlparse(gpt_url).netloc\n",
    "        self.path = urlparse(gpt_url).path\n",
    "        self.gpt_url = gpt_url\n",
    "\n",
    "    # ç”Ÿæˆurl\n",
    "    def create_url(self):\n",
    "        # ç”ŸæˆRFC1123æ ¼å¼çš„æ—¶é—´æˆ³\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "\n",
    "        # æ‹¼æ¥å­—ç¬¦ä¸²\n",
    "        signature_origin = \"host: \" + self.host + \"\\n\"\n",
    "        signature_origin += \"date: \" + date + \"\\n\"\n",
    "        signature_origin += \"GET \" + self.path + \" HTTP/1.1\"\n",
    "\n",
    "        # è¿›è¡Œhmac-sha256è¿›è¡ŒåŠ å¯†\n",
    "        signature_sha = hmac.new(self.APISecret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "\n",
    "        signature_sha_base64 = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "\n",
    "        authorization_origin = f'api_key=\"{self.APIKey}\", algorithm=\"hmac-sha256\", headers=\"host date request-line\", signature=\"{signature_sha_base64}\"'\n",
    "\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "\n",
    "        # å°†è¯·æ±‚çš„é‰´æƒå‚æ•°ç»„åˆä¸ºå­—å…¸\n",
    "        v = {\n",
    "            \"authorization\": authorization,\n",
    "            \"date\": date,\n",
    "            \"host\": self.host\n",
    "        }\n",
    "        # æ‹¼æ¥é‰´æƒå‚æ•°ï¼Œç”Ÿæˆurl\n",
    "        url = self.gpt_url + '?' + urlencode(v)\n",
    "        # æ­¤å¤„æ‰“å°å‡ºå»ºç«‹è¿æ¥æ—¶å€™çš„url,å‚è€ƒæœ¬demoçš„æ—¶å€™å¯å–æ¶ˆä¸Šæ–¹æ‰“å°çš„æ³¨é‡Šï¼Œæ¯”å¯¹ç›¸åŒå‚æ•°æ—¶ç”Ÿæˆçš„urlä¸è‡ªå·±ä»£ç ç”Ÿæˆçš„urlæ˜¯å¦ä¸€è‡´\n",
    "        return url\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketé”™è¯¯çš„å¤„ç†\n",
    "def on_error(ws, error):\n",
    "    print(\"### error:\", error)\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketå…³é—­çš„å¤„ç†\n",
    "def on_close(ws):\n",
    "    print(\"### closed ###\")\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketè¿æ¥å»ºç«‹çš„å¤„ç†\n",
    "def on_open(ws):\n",
    "    thread.start_new_thread(run, (ws,))\n",
    "\n",
    "\n",
    "def run(ws, *args):\n",
    "    data = json.dumps(gen_params(appid=ws.appid, query=ws.query, domain=ws.domain))\n",
    "    ws.send(data)\n",
    "\n",
    "\n",
    "\n",
    "def gen_params(appid, query, domain):\n",
    "    \"\"\"\n",
    "    é€šè¿‡appidå’Œç”¨æˆ·çš„æé—®æ¥ç”Ÿæˆè¯·å‚æ•°\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"header\": {\n",
    "            \"app_id\": appid,\n",
    "            \"uid\": \"1234\",           \n",
    "            # \"patch_id\": []    #æ¥å…¥å¾®è°ƒæ¨¡å‹ï¼Œå¯¹åº”æœåŠ¡å‘å¸ƒåçš„resourceid          \n",
    "        },\n",
    "        \"parameter\": {\n",
    "            \"chat\": {\n",
    "                \"domain\": domain,\n",
    "                \"temperature\": 0.5,\n",
    "                \"max_tokens\": 4096,\n",
    "                \"auditing\": \"default\",\n",
    "            }\n",
    "        },\n",
    "        \"payload\": {\n",
    "            \"message\": {\n",
    "                \"text\": [{\"role\": \"user\", \"content\": query}]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def main(appid, api_secret, api_key, gpt_url, domain, query):\n",
    "    output_queue = queue.Queue()\n",
    "    wsParam = Ws_Param(appid, api_key, api_secret, gpt_url)\n",
    "    websocket.enableTrace(False)\n",
    "    wsUrl = wsParam.create_url()\n",
    "    # æ”¶åˆ°websocketæ¶ˆæ¯çš„å¤„ç†\n",
    "    def on_message(ws, message):\n",
    "        # print(message)\n",
    "        data = json.loads(message)\n",
    "        code = data['header']['code']\n",
    "        if code != 0:\n",
    "            print(f'è¯·æ±‚é”™è¯¯: {code}, {data}')\n",
    "            ws.close()\n",
    "        else:\n",
    "            choices = data[\"payload\"][\"choices\"]\n",
    "            status = choices[\"status\"]\n",
    "            content = choices[\"text\"][0][\"content\"]\n",
    "            #print(content,end='')\n",
    "            output_queue.put(content)\n",
    "            if status == 2:\n",
    "                print(\"#### å…³é—­ä¼šè¯\")\n",
    "                ws.close()\n",
    "    ws = websocket.WebSocketApp(wsUrl, on_message=on_message, on_error=on_error, on_close=on_close, on_open=on_open)\n",
    "    ws.appid = appid\n",
    "    ws.query = query\n",
    "    ws.domain = domain\n",
    "    ws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\n",
    "    return ''.join([output_queue.get() for _ in range(output_queue.qsize())])\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "apiid = os.getenv(\"SPARK_APPID\")\n",
    "api_key = os.getenv(\"SPARK_API_KEY\")\n",
    "api_secret = os.getenv(\"SPARK_API_SECRET\")\n",
    "llm=Spark_LLM(appid=apiid, api_key=api_key, api_secret=api_secret)\n",
    "llm.invoke(\"ä½ å¥½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ‡é¢˜ï¼šç§‹æ—¥ç§è¯­\n",
      "\n",
      "ç§‹é£è½»æŠšï¼Œæ«å¶å¦‚ç«ã€‚æˆ‘åœ¨æ—é—´å°å¾„æ¼«æ­¥ï¼Œæ€ç»ªé£˜æ¸ºã€‚è½å¶é“ºå°±é‡‘é»„åœ°æ¯¯ï¼Œæ¯ä¸€æ­¥éƒ½è¸å‡ºæ²™æ²™çš„æ—‹å¾‹ã€‚æ ‘æ¢¢ä½è¯­ï¼Œä»¿ä½›åœ¨è¯‰è¯´ç€å­£èŠ‚çš„ç§˜å¯†ã€‚æˆ‘é—­ä¸Šçœ¼ç›ï¼Œè®©å¿ƒçµä¸è‡ªç„¶äº¤èï¼Œæ„Ÿå—é‚£ä»½å®é™ä¸å’Œè°ã€‚è¿™ä¸€åˆ»ï¼Œæˆ‘ä»¿ä½›å¬è§äº†ç§‹å¤©çš„ç§è¯­ã€‚#### å…³é—­ä¼šè¯\n",
      "### error: on_close() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import _thread as thread\n",
    "import os\n",
    "import time\n",
    "import base64\n",
    "\n",
    "import base64\n",
    "import datetime\n",
    "import hashlib\n",
    "import hmac\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import ssl\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from urllib.parse import urlencode\n",
    "from wsgiref.handlers import format_date_time\n",
    "\n",
    "import websocket\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "\n",
    "class Ws_Param(object):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self, APPID, APIKey, APISecret, gpt_url):\n",
    "        self.APPID = APPID\n",
    "        self.APIKey = APIKey\n",
    "        self.APISecret = APISecret\n",
    "        self.host = urlparse(gpt_url).netloc\n",
    "        self.path = urlparse(gpt_url).path\n",
    "        self.gpt_url = gpt_url\n",
    "\n",
    "    # ç”Ÿæˆurl\n",
    "    def create_url(self):\n",
    "        # ç”ŸæˆRFC1123æ ¼å¼çš„æ—¶é—´æˆ³\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "\n",
    "        # æ‹¼æ¥å­—ç¬¦ä¸²\n",
    "        signature_origin = \"host: \" + self.host + \"\\n\"\n",
    "        signature_origin += \"date: \" + date + \"\\n\"\n",
    "        signature_origin += \"GET \" + self.path + \" HTTP/1.1\"\n",
    "\n",
    "        # è¿›è¡Œhmac-sha256è¿›è¡ŒåŠ å¯†\n",
    "        signature_sha = hmac.new(self.APISecret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "\n",
    "        signature_sha_base64 = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "\n",
    "        authorization_origin = f'api_key=\"{self.APIKey}\", algorithm=\"hmac-sha256\", headers=\"host date request-line\", signature=\"{signature_sha_base64}\"'\n",
    "\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "\n",
    "        # å°†è¯·æ±‚çš„é‰´æƒå‚æ•°ç»„åˆä¸ºå­—å…¸\n",
    "        v = {\n",
    "            \"authorization\": authorization,\n",
    "            \"date\": date,\n",
    "            \"host\": self.host\n",
    "        }\n",
    "        # æ‹¼æ¥é‰´æƒå‚æ•°ï¼Œç”Ÿæˆurl\n",
    "        url = self.gpt_url + '?' + urlencode(v)\n",
    "        # æ­¤å¤„æ‰“å°å‡ºå»ºç«‹è¿æ¥æ—¶å€™çš„url,å‚è€ƒæœ¬demoçš„æ—¶å€™å¯å–æ¶ˆä¸Šæ–¹æ‰“å°çš„æ³¨é‡Šï¼Œæ¯”å¯¹ç›¸åŒå‚æ•°æ—¶ç”Ÿæˆçš„urlä¸è‡ªå·±ä»£ç ç”Ÿæˆçš„urlæ˜¯å¦ä¸€è‡´\n",
    "        return url\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketé”™è¯¯çš„å¤„ç†\n",
    "def on_error(ws, error):\n",
    "    print(\"### error:\", error)\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketå…³é—­çš„å¤„ç†\n",
    "def on_close(ws):\n",
    "    print(\"### closed ###\")\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketè¿æ¥å»ºç«‹çš„å¤„ç†\n",
    "def on_open(ws):\n",
    "    thread.start_new_thread(run, (ws,))\n",
    "\n",
    "\n",
    "def run(ws, *args):\n",
    "    data = json.dumps(gen_params(appid=ws.appid, query=ws.query, domain=ws.domain))\n",
    "    ws.send(data)\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketæ¶ˆæ¯çš„å¤„ç†\n",
    "def on_message(ws, message):\n",
    "    # print(message)\n",
    "    data = json.loads(message)\n",
    "    code = data['header']['code']\n",
    "    if code != 0:\n",
    "        print(f'è¯·æ±‚é”™è¯¯: {code}, {data}')\n",
    "        ws.close()\n",
    "    else:\n",
    "        choices = data[\"payload\"][\"choices\"]\n",
    "        status = choices[\"status\"]\n",
    "        content = choices[\"text\"][0][\"content\"]\n",
    "        print(content,end='')\n",
    "        if status == 2:\n",
    "            print(\"#### å…³é—­ä¼šè¯\")\n",
    "            ws.close()\n",
    "\n",
    "\n",
    "def gen_params(appid, query, domain):\n",
    "    \"\"\"\n",
    "    é€šè¿‡appidå’Œç”¨æˆ·çš„æé—®æ¥ç”Ÿæˆè¯·å‚æ•°\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"header\": {\n",
    "            \"app_id\": appid,\n",
    "            \"uid\": \"1234\",           \n",
    "            # \"patch_id\": []    #æ¥å…¥å¾®è°ƒæ¨¡å‹ï¼Œå¯¹åº”æœåŠ¡å‘å¸ƒåçš„resourceid          \n",
    "        },\n",
    "        \"parameter\": {\n",
    "            \"chat\": {\n",
    "                \"domain\": domain,\n",
    "                \"temperature\": 0.5,\n",
    "                \"max_tokens\": 4096,\n",
    "                \"auditing\": \"default\",\n",
    "            }\n",
    "        },\n",
    "        \"payload\": {\n",
    "            \"message\": {\n",
    "                \"text\": [{\"role\": \"user\", \"content\": query}]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def main(appid, api_secret, api_key, gpt_url, domain, query):\n",
    "    wsParam = Ws_Param(appid, api_key, api_secret, gpt_url)\n",
    "    websocket.enableTrace(False)\n",
    "    wsUrl = wsParam.create_url()\n",
    "\n",
    "    ws = websocket.WebSocketApp(wsUrl, on_message=on_message, on_error=on_error, on_close=on_close, on_open=on_open)\n",
    "    ws.appid = appid\n",
    "    ws.query = query\n",
    "    ws.domain = domain\n",
    "    ws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    import os\n",
    "    apiid = os.getenv(\"SPARK_APPID\")\n",
    "    api_key = os.getenv(\"SPARK_API_KEY\")\n",
    "    api_secret = os.getenv(\"SPARK_API_SECRET\")\n",
    "    main(\n",
    "        appid=apiid,\n",
    "        api_secret=api_secret,\n",
    "        api_key=api_key,\n",
    "        #appidã€api_secretã€api_keyä¸‰ä¸ªæœåŠ¡è®¤è¯ä¿¡æ¯è¯·å‰å¾€å¼€æ”¾å¹³å°æ§åˆ¶å°æŸ¥çœ‹ï¼ˆhttps://console.xfyun.cn/services/bm35ï¼‰\n",
    "        gpt_url=\"wss://spark-api.xf-yun.com/v3.5/chat\",\n",
    "        # Spark_url = \"ws://spark-api.xf-yun.com/v3.1/chat\"  # v3.0ç¯å¢ƒçš„åœ°å€\n",
    "        # Spark_url = \"ws://spark-api.xf-yun.com/v2.1/chat\"  # v2.0ç¯å¢ƒçš„åœ°å€\n",
    "        # Spark_url = \"ws://spark-api.xf-yun.com/v1.1/chat\"  # v1.5ç¯å¢ƒçš„åœ°å€\n",
    "        domain=\"generalv3.5\",\n",
    "        # domain = \"generalv3\"    # v3.0ç‰ˆæœ¬\n",
    "        # domain = \"generalv2\"    # v2.0ç‰ˆæœ¬\n",
    "        # domain = \"general\"    # v2.0ç‰ˆæœ¬\n",
    "        query=\"ç»™æˆ‘å†™ä¸€ç¯‡100å­—çš„ä½œæ–‡\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'æ‚¨å¥½ï¼Œæˆ‘æ˜¯ç§‘å¤§è®¯é£ç ”å‘çš„è®¤çŸ¥æ™ºèƒ½å¤§æ¨¡å‹ï¼Œæˆ‘çš„åå­—å«è®¯é£æ˜Ÿç«è®¤çŸ¥å¤§æ¨¡å‹ã€‚æˆ‘å¯ä»¥å’Œäººç±»è¿›è¡Œè‡ªç„¶äº¤æµï¼Œè§£ç­”é—®é¢˜ï¼Œé«˜æ•ˆå®Œæˆå„é¢†åŸŸè®¤çŸ¥æ™ºèƒ½éœ€æ±‚ã€‚'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Mapping, Optional, Dict, Union, Tuple\n",
    "from pydantic import Field\n",
    "from test_MYLLM import CustomLLM\n",
    "import json\n",
    "import requests\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "import _thread as thread\n",
    "import base64\n",
    "import datetime\n",
    "import hashlib\n",
    "import hmac\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import ssl\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from urllib.parse import urlencode\n",
    "from wsgiref.handlers import format_date_time\n",
    "import websocket  # ä½¿ç”¨websocket_client\n",
    "import queue\n",
    "\n",
    "class Spark_LLM(CustomLLM):\n",
    "    # è®¯é£æ˜Ÿç«å¤§æ¨¡å‹çš„è‡ªå®šä¹‰ LLM\n",
    "    # URL\n",
    "    url : str = \"wss://spark-api.xf-yun.com/v3.5/chat\"\n",
    "    # APPID\n",
    "    appid : str = None\n",
    "    # APISecret\n",
    "    api_secret : str = None\n",
    "    # Domain\n",
    "    domain :str = \"generalv3.5\"\n",
    "    # max_token\n",
    "    max_tokens : int = 4096\n",
    "\n",
    "    def getText(self, role, content, text = []):\n",
    "        # role æ˜¯æŒ‡å®šè§’è‰²ï¼Œcontent æ˜¯ prompt å†…å®¹\n",
    "        jsoncon = {}\n",
    "        jsoncon[\"role\"] = role\n",
    "        jsoncon[\"content\"] = content\n",
    "        text.append(jsoncon)\n",
    "        return text\n",
    "\n",
    "    def _call(self, prompt : str, stop: Optional[List[str]] = None,\n",
    "                run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "                **kwargs: Any):\n",
    "        if self.api_key == None or self.appid == None or self.api_secret == None:\n",
    "            # ä¸‰ä¸ª Key å‡å­˜åœ¨æ‰å¯ä»¥æ­£å¸¸è°ƒç”¨\n",
    "            print(\"è¯·å¡«å…¥ Key\")\n",
    "            raise ValueError(\"Key ä¸å­˜åœ¨\")\n",
    "        # å°† Prompt å¡«å……åˆ°æ˜Ÿç«æ ¼å¼\n",
    "        question = self.getText(\"user\", prompt)\n",
    "        # å‘èµ·è¯·æ±‚\n",
    "        try:\n",
    "            response = spark_main(self.appid,self.api_key,self.api_secret,self.url,self.domain,question, self.temperature, self.max_tokens)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"è¯·æ±‚å¤±è´¥\")\n",
    "            return \"è¯·æ±‚å¤±è´¥\"\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"Spark\"\n",
    "\n",
    "class Ws_Param(object):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self, APPID, APIKey, APISecret, Spark_url):\n",
    "        self.APPID = APPID\n",
    "        self.APIKey = APIKey\n",
    "        self.APISecret = APISecret\n",
    "        self.host = urlparse(Spark_url).netloc\n",
    "        self.path = urlparse(Spark_url).path\n",
    "        self.Spark_url = Spark_url\n",
    "        # è‡ªå®šä¹‰\n",
    "        self.temperature = 0\n",
    "        self.max_tokens = 2048\n",
    "\n",
    "    # ç”Ÿæˆurl\n",
    "    def create_url(self):\n",
    "        # ç”ŸæˆRFC1123æ ¼å¼çš„æ—¶é—´æˆ³\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "\n",
    "        # æ‹¼æ¥å­—ç¬¦ä¸²\n",
    "        signature_origin = \"host: \" + self.host + \"\\n\"\n",
    "        signature_origin += \"date: \" + date + \"\\n\"\n",
    "        signature_origin += \"GET \" + self.path + \" HTTP/1.1\"\n",
    "\n",
    "        # è¿›è¡Œhmac-sha256è¿›è¡ŒåŠ å¯†\n",
    "        signature_sha = hmac.new(self.APISecret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "\n",
    "        signature_sha_base64 = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "\n",
    "        authorization_origin = f'api_key=\"{self.APIKey}\", algorithm=\"hmac-sha256\", headers=\"host date request-line\", signature=\"{signature_sha_base64}\"'\n",
    "\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "\n",
    "        # å°†è¯·æ±‚çš„é‰´æƒå‚æ•°ç»„åˆä¸ºå­—å…¸\n",
    "        v = {\n",
    "            \"authorization\": authorization,\n",
    "            \"date\": date,\n",
    "            \"host\": self.host\n",
    "        }\n",
    "        # æ‹¼æ¥é‰´æƒå‚æ•°ï¼Œç”Ÿæˆurl\n",
    "        url = self.Spark_url + '?' + urlencode(v)\n",
    "        # æ­¤å¤„æ‰“å°å‡ºå»ºç«‹è¿æ¥æ—¶å€™çš„url,å‚è€ƒæœ¬demoçš„æ—¶å€™å¯å–æ¶ˆä¸Šæ–¹æ‰“å°çš„æ³¨é‡Šï¼Œæ¯”å¯¹ç›¸åŒå‚æ•°æ—¶ç”Ÿæˆçš„urlä¸è‡ªå·±ä»£ç ç”Ÿæˆçš„urlæ˜¯å¦ä¸€è‡´\n",
    "        return url\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketé”™è¯¯çš„å¤„ç†\n",
    "def on_error(ws, error):\n",
    "    print(\"### error:\", error)\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketå…³é—­çš„å¤„ç†\n",
    "def on_close(ws,one,two):\n",
    "    print(\" \")\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketè¿æ¥å»ºç«‹çš„å¤„ç†\n",
    "def on_open(ws):\n",
    "    thread.start_new_thread(run, (ws,))\n",
    "\n",
    "\n",
    "def run(ws, *args):\n",
    "    data = json.dumps(gen_params(appid=ws.appid, domain= ws.domain,question=ws.question, temperature = ws.temperature, max_tokens = ws.max_tokens))\n",
    "    ws.send(data)\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketæ¶ˆæ¯çš„å¤„ç†\n",
    "def on_message(ws, message):\n",
    "    # print(message)\n",
    "    data = json.loads(message)\n",
    "    code = data['header']['code']\n",
    "    if code != 0:\n",
    "        print(f'è¯·æ±‚é”™è¯¯: {code}, {data}')\n",
    "        ws.close()\n",
    "    else:\n",
    "        choices = data[\"payload\"][\"choices\"]\n",
    "        status = choices[\"status\"]\n",
    "        content = choices[\"text\"][0][\"content\"]\n",
    "        print(content,end =\"\")\n",
    "        global answer\n",
    "        answer += content\n",
    "        # print(1)\n",
    "        if status == 2:\n",
    "            ws.close()\n",
    "\n",
    "\n",
    "def gen_params(appid, domain,question, temperature, max_tokens):\n",
    "    \"\"\"\n",
    "    é€šè¿‡appidå’Œç”¨æˆ·çš„æé—®æ¥ç”Ÿæˆè¯·å‚æ•°\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"header\": {\n",
    "            \"app_id\": appid,\n",
    "            \"uid\": \"1234\"\n",
    "        },\n",
    "        \"parameter\": {\n",
    "            \"chat\": {\n",
    "                \"domain\": domain,\n",
    "                \"random_threshold\": 0.5,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\" : temperature,\n",
    "                \"auditing\": \"default\"\n",
    "            }\n",
    "        },\n",
    "        \"payload\": {\n",
    "            \"message\": {\n",
    "                \"text\": question\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def spark_main(appid, api_key, api_secret, Spark_url,domain, question, temperature, max_tokens):\n",
    "    # print(\"æ˜Ÿç«:\")\n",
    "    output_queue = queue.Queue()\n",
    "    def on_message(ws, message):\n",
    "        data = json.loads(message)\n",
    "        code = data['header']['code']\n",
    "        if code != 0:\n",
    "            print(f'è¯·æ±‚é”™è¯¯: {code}, {data}')\n",
    "            ws.close()\n",
    "        else:\n",
    "            choices = data[\"payload\"][\"choices\"]\n",
    "            status = choices[\"status\"]\n",
    "            content = choices[\"text\"][0][\"content\"]\n",
    "            # print(content, end='')\n",
    "            # å°†è¾“å‡ºå€¼æ”¾å…¥é˜Ÿåˆ—\n",
    "            output_queue.put(content)\n",
    "            if status == 2: \n",
    "                ws.close()\n",
    "\n",
    "    wsParam = Ws_Param(appid, api_key, api_secret, Spark_url)\n",
    "    websocket.enableTrace(False)\n",
    "    wsUrl = wsParam.create_url()\n",
    "    ws = websocket.WebSocketApp(wsUrl, on_message=on_message, on_error=on_error, on_close=on_close, on_open=on_open)\n",
    "    ws.appid = appid\n",
    "    ws.question = question\n",
    "    ws.domain = domain\n",
    "    ws.temperature = temperature\n",
    "    ws.max_tokens = max_tokens\n",
    "    ws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\n",
    "    return ''.join([output_queue.get() for _ in range(output_queue.qsize())])\n",
    "\n",
    "import os\n",
    "apiid = os.getenv(\"SPARK_APPID\")\n",
    "api_key = os.getenv(\"SPARK_API_KEY\")\n",
    "api_secret = os.getenv(\"SPARK_API_SECRET\")\n",
    "llm=Spark_LLM(appid=apiid, api_key=api_key, api_secret=api_secret)\n",
    "llm.invoke(\"ä½ å¥½, ä½ æ˜¯è°ï¼Ÿ\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_queue.qsize() = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Mapping, Optional, Dict, Union, Tuple\n",
    "from pydantic import Field\n",
    "from test_MYLLM import CustomLLM\n",
    "import json\n",
    "import requests\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "import _thread as thread\n",
    "import base64\n",
    "import datetime\n",
    "import hashlib\n",
    "import hmac\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import ssl\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from urllib.parse import urlencode\n",
    "from wsgiref.handlers import format_date_time\n",
    "import websocket  # ä½¿ç”¨websocket_client\n",
    "import queue\n",
    "\n",
    "class Spark_LLM(CustomLLM):\n",
    "    # è®¯é£æ˜Ÿç«å¤§æ¨¡å‹çš„è‡ªå®šä¹‰ LLM\n",
    "    # URL\n",
    "    url : str = \"wss://spark-api.xf-yun.com/v3.1/chat\"\n",
    "    # APPID\n",
    "    appid : str = None\n",
    "    # APISecret\n",
    "    api_secret : str = None\n",
    "    # Domain\n",
    "    domain :str = \"generalv3\"\n",
    "    # max_token\n",
    "    max_tokens : int = 4096\n",
    "\n",
    "    def getText(self, role, content, text = []):\n",
    "        # role æ˜¯æŒ‡å®šè§’è‰²ï¼Œcontent æ˜¯ prompt å†…å®¹\n",
    "        jsoncon = {}\n",
    "        jsoncon[\"role\"] = role\n",
    "        jsoncon[\"content\"] = content\n",
    "        text.append(jsoncon)\n",
    "        return text\n",
    "\n",
    "    def _call(self, prompt : str, stop: Optional[List[str]] = None,\n",
    "                run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "                **kwargs: Any):\n",
    "        if self.api_key == None or self.appid == None or self.api_secret == None:\n",
    "            # ä¸‰ä¸ª Key å‡å­˜åœ¨æ‰å¯ä»¥æ­£å¸¸è°ƒç”¨\n",
    "            print(\"è¯·å¡«å…¥ Key\")\n",
    "            raise ValueError(\"Key ä¸å­˜åœ¨\")\n",
    "        # å°† Prompt å¡«å……åˆ°æ˜Ÿç«æ ¼å¼\n",
    "        question = self.getText(\"user\", prompt)\n",
    "        # å‘èµ·è¯·æ±‚\n",
    "        try:\n",
    "            response = spark_main(self.appid,self.api_key,self.api_secret,self.url,self.domain,question, self.temperature, self.max_tokens)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"è¯·æ±‚å¤±è´¥\")\n",
    "            return \"è¯·æ±‚å¤±è´¥\"\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"Spark\"\n",
    "\n",
    "class Ws_Param(object):\n",
    "    # åˆå§‹åŒ–\n",
    "    def __init__(self, APPID, APIKey, APISecret, Spark_url):\n",
    "        self.APPID = APPID\n",
    "        self.APIKey = APIKey\n",
    "        self.APISecret = APISecret\n",
    "        self.host = urlparse(Spark_url).netloc\n",
    "        self.path = urlparse(Spark_url).path\n",
    "        self.Spark_url = Spark_url\n",
    "        # è‡ªå®šä¹‰\n",
    "        self.temperature = 0\n",
    "        self.max_tokens = 2048\n",
    "\n",
    "    # ç”Ÿæˆurl\n",
    "    def create_url(self):\n",
    "        # ç”ŸæˆRFC1123æ ¼å¼çš„æ—¶é—´æˆ³\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "\n",
    "        # æ‹¼æ¥å­—ç¬¦ä¸²\n",
    "        signature_origin = \"host: \" + self.host + \"\\n\"\n",
    "        signature_origin += \"date: \" + date + \"\\n\"\n",
    "        signature_origin += \"GET \" + self.path + \" HTTP/1.1\"\n",
    "\n",
    "        # è¿›è¡Œhmac-sha256è¿›è¡ŒåŠ å¯†\n",
    "        signature_sha = hmac.new(self.APISecret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "\n",
    "        signature_sha_base64 = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "\n",
    "        authorization_origin = f'api_key=\"{self.APIKey}\", algorithm=\"hmac-sha256\", headers=\"host date request-line\", signature=\"{signature_sha_base64}\"'\n",
    "\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "\n",
    "        # å°†è¯·æ±‚çš„é‰´æƒå‚æ•°ç»„åˆä¸ºå­—å…¸\n",
    "        v = {\n",
    "            \"authorization\": authorization,\n",
    "            \"date\": date,\n",
    "            \"host\": self.host\n",
    "        }\n",
    "        # æ‹¼æ¥é‰´æƒå‚æ•°ï¼Œç”Ÿæˆurl\n",
    "        url = self.Spark_url + '?' + urlencode(v)\n",
    "        # æ­¤å¤„æ‰“å°å‡ºå»ºç«‹è¿æ¥æ—¶å€™çš„url,å‚è€ƒæœ¬demoçš„æ—¶å€™å¯å–æ¶ˆä¸Šæ–¹æ‰“å°çš„æ³¨é‡Šï¼Œæ¯”å¯¹ç›¸åŒå‚æ•°æ—¶ç”Ÿæˆçš„urlä¸è‡ªå·±ä»£ç ç”Ÿæˆçš„urlæ˜¯å¦ä¸€è‡´\n",
    "        return url\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketé”™è¯¯çš„å¤„ç†\n",
    "def on_error(ws, error):\n",
    "    print(\"### error:\", error)\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketå…³é—­çš„å¤„ç†\n",
    "def on_close(ws,one,two):\n",
    "    pass\n",
    "\n",
    "\n",
    "# æ”¶åˆ°websocketè¿æ¥å»ºç«‹çš„å¤„ç†\n",
    "def on_open(ws):\n",
    "    thread.start_new_thread(run, (ws,))\n",
    "\n",
    "\n",
    "def run(ws, *args):\n",
    "    data = json.dumps(gen_params(appid=ws.appid, domain= ws.domain,question=ws.question, temperature = ws.temperature, max_tokens = ws.max_tokens))\n",
    "    ws.send(data)\n",
    "\n",
    "\n",
    "# # æ”¶åˆ°websocketæ¶ˆæ¯çš„å¤„ç†\n",
    "# def on_message(ws, message):\n",
    "#     # print(message)\n",
    "#     data = json.loads(message)\n",
    "#     code = data['header']['code']\n",
    "#     if code != 0:\n",
    "#         print(f'è¯·æ±‚é”™è¯¯: {code}, {data}')\n",
    "#         ws.close()\n",
    "#     else:\n",
    "#         choices = data[\"payload\"][\"choices\"]\n",
    "#         status = choices[\"status\"]\n",
    "#         content = choices[\"text\"][0][\"content\"]\n",
    "#         print(content,end =\"\")\n",
    "#         global answer\n",
    "#         answer += content\n",
    "#         # print(1)\n",
    "#         if status == 2:\n",
    "#             ws.close()\n",
    "\n",
    "\n",
    "def gen_params(appid, domain,question, temperature, max_tokens):\n",
    "    \"\"\"\n",
    "    é€šè¿‡appidå’Œç”¨æˆ·çš„æé—®æ¥ç”Ÿæˆè¯·å‚æ•°\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"header\": {\n",
    "            \"app_id\": appid,\n",
    "            \"uid\": \"1234\"\n",
    "        },\n",
    "        \"parameter\": {\n",
    "            \"chat\": {\n",
    "                \"domain\": domain,\n",
    "                \"random_threshold\": 0.5,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\" : temperature,\n",
    "                \"auditing\": \"default\"\n",
    "            }\n",
    "        },\n",
    "        \"payload\": {\n",
    "            \"message\": {\n",
    "                \"text\": question\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def spark_main(appid, api_key, api_secret, Spark_url,domain, question, temperature, max_tokens):\n",
    "    # print(\"æ˜Ÿç«:\")\n",
    "    output_queue = queue.Queue()\n",
    "    def on_message(ws, message):\n",
    "        data = json.loads(message)\n",
    "        code = data['header']['code']\n",
    "        if code != 0:\n",
    "            print(f'è¯·æ±‚é”™è¯¯: {code}, {data}')\n",
    "            ws.close()\n",
    "        else:\n",
    "            choices = data[\"payload\"][\"choices\"]\n",
    "            status = choices[\"status\"]\n",
    "            content = choices[\"text\"][0][\"content\"].strip()\n",
    "\n",
    "            # content = '\\n'.join(line for line in content.splitlines() if line.strip())\n",
    "            if content:\n",
    "                # print(content, end='')\n",
    "                output_queue.put(content)\n",
    "            if status == 2: \n",
    "                # print(f\"status == 2, output_queue = {output_queue.qsize()}\")\n",
    "                ws.close()\n",
    "\n",
    "    wsParam = Ws_Param(appid, api_key, api_secret, Spark_url)\n",
    "    websocket.enableTrace(False)\n",
    "    wsUrl = wsParam.create_url()\n",
    "    ws = websocket.WebSocketApp(wsUrl, on_message=on_message, on_error=on_error, on_close=on_close, on_open=on_open)\n",
    "    ws.appid = appid\n",
    "    ws.question = question\n",
    "    ws.domain = domain\n",
    "    ws.temperature = temperature\n",
    "    ws.max_tokens = max_tokens\n",
    "    print(f\"output_queue.qsize() = {output_queue.qsize()}\")\n",
    "    # print(f\"wsUrl = {wsUrl}\")\n",
    "    ws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\n",
    "    \n",
    "    # print([output_queue.get() for _ in range(output_queue.qsize())])\n",
    "    return (''.join([output_queue.get() for _ in range(output_queue.qsize())]).strip())\n",
    "\n",
    "import os\n",
    "apiid = os.getenv(\"SPARK_APPID\")\n",
    "api_key = os.getenv(\"SPARK_API_KEY\")\n",
    "api_secret = os.getenv(\"SPARK_API_SECRET\")\n",
    "llm=Spark_LLM(appid=apiid, api_key=api_key, api_secret=api_secret)\n",
    "print(llm.invoke(\"ä½ å¥½\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MChat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
