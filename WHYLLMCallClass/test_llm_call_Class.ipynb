{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchainLLM模板\n",
    "from typing import Any, Dict, Iterator, List, Mapping, Optional\n",
    "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from langchain_core.outputs import GenerationChunk\n",
    "\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    \"\"\"A custom chat model that echoes the first `n` characters of the input.\n",
    "\n",
    "    When contributing an implementation to LangChain, carefully document\n",
    "    the model including the initialization parameters, include\n",
    "    an example of how to initialize the model and include any relevant\n",
    "    links to the underlying models documentation or API.\n",
    "\n",
    "    Example:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            model = CustomChatModel(n=2)\n",
    "            result = model.invoke([HumanMessage(content=\"hello\")])\n",
    "            result = model.batch([[HumanMessage(content=\"hello\")],\n",
    "                                 [HumanMessage(content=\"world\")]])\n",
    "    \"\"\"\n",
    "\n",
    "    n: int\n",
    "    \"\"\"The number of characters from the last message of the prompt to be echoed.\"\"\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        \"\"\"Run the LLM on the given input.\n",
    "\n",
    "        Override this method to implement the LLM logic.\n",
    "\n",
    "        Args:\n",
    "            prompt: The prompt to generate from.\n",
    "            stop: Stop words to use when generating. Model output is cut off at the\n",
    "                first occurrence of any of the stop substrings.\n",
    "                If stop tokens are not supported consider raising NotImplementedError.\n",
    "            run_manager: Callback manager for the run.\n",
    "            **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
    "                to the model provider API call.\n",
    "\n",
    "        Returns:\n",
    "            The model output as a string. Actual completions SHOULD NOT include the prompt.\n",
    "        \"\"\"\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        return prompt[: self.n]\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[GenerationChunk]:\n",
    "        \"\"\"Stream the LLM on the given prompt.\n",
    "\n",
    "        This method should be overridden by subclasses that support streaming.\n",
    "\n",
    "        If not implemented, the default behavior of calls to stream will be to\n",
    "        fallback to the non-streaming version of the model and return\n",
    "        the output as a single chunk.\n",
    "\n",
    "        Args:\n",
    "            prompt: The prompt to generate from.\n",
    "            stop: Stop words to use when generating. Model output is cut off at the\n",
    "                first occurrence of any of these substrings.\n",
    "            run_manager: Callback manager for the run.\n",
    "            **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
    "                to the model provider API call.\n",
    "\n",
    "        Returns:\n",
    "            An iterator of GenerationChunks.\n",
    "        \"\"\"\n",
    "        for char in prompt[: self.n]:\n",
    "            chunk = GenerationChunk(text=char)\n",
    "            if run_manager:\n",
    "                run_manager.on_llm_new_token(chunk.text, chunk=chunk)\n",
    "\n",
    "            yield chunk\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return a dictionary of identifying parameters.\"\"\"\n",
    "        return {\n",
    "            # The model name allows users to specify custom token counting\n",
    "            # rules in LLM monitoring applications (e.g., in LangSmith users\n",
    "            # can provide per token pricing for their model and monitor\n",
    "            # costs for the given LLM.)\n",
    "            \"model_name\": \"CustomChatModel\",\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Get the type of language model used by this chat model. Used for logging purposes only.\"\"\"\n",
    "        return \"custom\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我的LLM模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Mapping\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from typing import Dict, Any\n",
    "from pydantic import Field\n",
    "class CustomLLM(LLM):\n",
    "    \"\"\"自定义语言模型类，继承自LLM基类。\n",
    "\n",
    "    属性:\n",
    "        model_name: 模型名称。\n",
    "        url: 模型平台的URL，需要先去某个url获得access_token,然后再去另一个url获得模型的结果。（可选）\n",
    "        api_key: API密钥。（可选）\n",
    "        appid: 应用ID。（可选）\n",
    "        api_secret: API密码。（可选）\n",
    "        access_token: 模型平台的访问令牌。（可选）\n",
    "        timeout: 模型平台的超时时间。\n",
    "        temperature: 控制生成文本的随机性的参数，值越大，输出的随机性越大。\n",
    "        model_kwargs: 模型的其他可选参数。\n",
    "    \"\"\"\n",
    "\n",
    "    url: str = None\n",
    "\n",
    "    api_key: str = None\n",
    "\n",
    "    appid: str = None\n",
    "\n",
    "    api_secret: str = None\n",
    "\n",
    "    access_token: str = None\n",
    "\n",
    "    request_timeout: float = 50.0\n",
    "\n",
    "    temperature: float = 0.36\n",
    "\n",
    "    # # 必备的可选参数\n",
    "    # model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    # 定义一个返回默认参数的方法\n",
    "    @property\n",
    "    def _default_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"获取调用默认参数。\"\"\"\n",
    "        normal_params = {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"request_timeout\": self.request_timeout,\n",
    "            }\n",
    "        return {**normal_params}\n",
    "    \n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {**{\"model_name\": self.model_name}, **self._default_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 千帆平台自定义LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是零一万物开发的智能助手，我叫 Yi，我是由零一万物的优秀工程师们一起开发的。我可以回答你的问题，提供信息，帮助你解决问题。请问有什么我可以帮助你的？\n"
     ]
    }
   ],
   "source": [
    "# 向授权服务地址 https://aip.baidubce.com/oauth/2.0/token 发送请求（推荐使用POST）。\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import Dict, List, Optional, Any\n",
    "from test_MYLLM import CustomLLM\n",
    "from pydantic import Field\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "def get_access_token(API_KEY: str, SECRET_KEY: str):\n",
    "    \"\"\"\n",
    "    使用 AK，SK 生成鉴权签名（Access Token）\n",
    "    :return: access_token，或是None(如果错误)\n",
    "    \"\"\"\n",
    "    url = \"https://aip.baidubce.com/oauth/2.0/token\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    params = {\"grant_type\": \"client_credentials\", \"client_id\": API_KEY, \"client_secret\": SECRET_KEY}\n",
    "    return str(requests.post(url, params=params).json().get(\"access_token\"))\n",
    "\n",
    "class QianFanLLM(CustomLLM):\n",
    "    model_name: str = None\n",
    "    \"\"\"\n",
    "    model_name: 可选择\n",
    "    - \n",
    "    \"\"\"\n",
    "    url: str = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/yi_34b_chat?access_token={}\"\n",
    "    api_key: str = None\n",
    "    appid: str = None\n",
    "    api_secret: str = None\n",
    "    access_token: str = None\n",
    "    request_timeout: float = 50.0\n",
    "    # model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "    def init_access_token(self):\n",
    "        # 当模型初始化时，获取access_token\n",
    "        # 同时需要有api_key和api_secret\n",
    "        if self.api_key is None or self.api_secret is None:\n",
    "            raise ValueError(\"api_key and api_secret are required.\")\n",
    "        else:\n",
    "            try:\n",
    "                self.access_token = get_access_token(self.api_key, self.api_secret)\n",
    "                # print(\"access_token: \", self.access_token)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                raise  # 重新抛出异常\n",
    "    \n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        # 调用模型的逻辑\n",
    "        if self.access_token is None:\n",
    "            self.init_access_token()\n",
    "        # 发送请求到api调用的url\n",
    "        url = self.url.format(self.access_token)\n",
    "\n",
    "        # 配置POST参数\n",
    "        payload = json.dumps({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \n",
    "                    \"content\": prompt}\n",
    "                    ],\n",
    "                'temperature': self.temperature\n",
    "        })\n",
    "\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "        response = requests.request(\"POST\", url, headers=headers, data=payload, timeout=self.request_timeout)\n",
    "        # 返回结果\n",
    "        # print(response)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(\"Request failed with status code: {}\".format(response.status_code))\n",
    "        else:\n",
    "            # 返回的是一个 Json 字符串\n",
    "            text = json.loads(response.text)\n",
    "            # print(js)\n",
    "            return text[\"result\"]\n",
    "        \n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            **{\"model\": self.model_name},\n",
    "            **super()._identifying_params,\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"QianFanLLM\"\n",
    "            \n",
    "\n",
    "# 测试QianFanLLM\n",
    "model = QianFanLLM(model_name=\"Yi-34B-Chat\", \n",
    "                   api_key=\"HnngI6IOybeRJyLgvtowIRUt\", \n",
    "                   api_secret=\"Vx7tFMIdGDrouCsyBRuChmbNBHhlMM2e\")\n",
    "result = model.invoke(\"你好\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*千帆测试成功*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions_pro?access_token=\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions_pro_preemptible?access_token=\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/eb-instant?access_token={}\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/yi_34b_chat?access_token=\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions?access_token=\"\n",
    "\n",
    "\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/eb-instant?access_token={access_token}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 智谱LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好👋！我是人工智能助手智谱清言（ChatGLM），很高兴见到你，欢迎问我任何问题。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import Dict, List, Optional, Any\n",
    "from test_MYLLM import CustomLLM\n",
    "import zhipuai\n",
    "from langchain.pydantic_v1 import Field, root_validator\n",
    "from langchain.utils import get_from_dict_or_env\n",
    "from zhipuai import ZhipuAI\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "class ZhiPuLLM(CustomLLM):\n",
    "    url: str = \"https://open.bigmodel.cn/api/paas/v4/chat/completions\"\n",
    "    model_name: str = None\n",
    "    api_key: str = None\n",
    "    appid: str = None\n",
    "    api_secret: str = None\n",
    "    access_token: str = None\n",
    "    client: Any\n",
    "    request_timeout: float = 50.0\n",
    "    temperature: float = 0.36\n",
    "    model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    # 验证zhipu_api_key\n",
    "    @root_validator\n",
    "    def validate_api_key(cls, values: Dict) -> Dict:\n",
    "        values[\"ZHIPUAI_API_KEY\"] = get_from_dict_or_env(values,\"zhipuai_api_key\", \"ZHIPUAI_API_KEY\")\n",
    "\n",
    "        try:\n",
    "            zhipuai.api_key = values[\"ZHIPUAI_API_KEY\"]\n",
    "            # print(zhipuai.api_key)\n",
    "            values[\"client\"] = ZhipuAI(api_key=zhipuai.api_key)\n",
    "            # print(values[\"client\"])\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"api_key is required.\")\n",
    "\n",
    "        return values\n",
    "    \n",
    "\n",
    "\n",
    "    @property\n",
    "    def _default_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get the default parameters.\"\"\"\n",
    "        normal_params = {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"request_timeout\": self.request_timeout,\n",
    "            \"model\": self.model_name,\n",
    "        }\n",
    "        return {**normal_params, **self.model_kwargs}\n",
    "\n",
    "\n",
    "    def _convert_prompt_msg_params(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        **kwargs: Any,\n",
    "    ) -> dict:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        return {\n",
    "            **{\"model\": self.model_name, \"messages\": messages},\n",
    "            **kwargs,\n",
    "        }\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:     \n",
    "\n",
    "                # 配置POST参数\n",
    "        payload = json.dumps({\n",
    "\n",
    "            \"model\": self.model_name,\n",
    "\n",
    "            \"messages\": [\n",
    "                    {\"role\": \"user\", \n",
    "                    \"content\": prompt}\n",
    "                    ],\n",
    "                'temperature': self.temperature\n",
    "        })\n",
    "\n",
    "\n",
    "        headers = {\n",
    "            'Authorization': 'Bearer ' + self.api_key,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "               }\n",
    "\n",
    "        response = requests.request(\"POST\", self.url, headers=headers, data=payload, timeout=self.request_timeout)\n",
    "        # print(response)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(\"Request failed with status code: {}\".format(response.status_code))\n",
    "        else:\n",
    "            # 返回的是一个 Json 字符串\n",
    "            text = json.loads(response.text)\n",
    "            return text[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "\n",
    "        # return response.choices[0].message.content\n",
    "            \n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            **super()._identifying_params,\n",
    "        }\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return type of llm.\"\"\"\n",
    "        return \"ZhiPuLLM\"\n",
    "\n",
    "# 测试ZhiPuLLM\n",
    "model = ZhiPuLLM(model_name = \"glm-3-turbo\",\n",
    "                  api_key = \"26128e545ddd8a44c6588c4d530a5fbe.hj6klSWNSFWnli9p\",\n",
    "                  )\n",
    "\n",
    "print(model.invoke(\"你好\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*智谱测试成功*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 星火spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好\n",
      "### error: Handshake status 401 Unauthorized -+-+- {'date': 'Thu, 25 Apr 2024 13:56:06 GMT', 'content-type': 'application/json; charset=utf-8', 'connection': 'keep-alive', 'content-length': '76', 'server': 'kong/1.3.0'} -+-+- b'{\"message\":\"HMAC signature cannot be verified: fail to retrieve credential\"}'\n",
      "### error: on_close() takes 1 positional argument but 3 were given\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import _thread as thread\n",
    "import os\n",
    "import queue\n",
    "import time\n",
    "import base64\n",
    "\n",
    "import base64\n",
    "import datetime\n",
    "import hashlib\n",
    "import hmac\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import ssl\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from urllib.parse import urlencode\n",
    "from wsgiref.handlers import format_date_time\n",
    "\n",
    "import websocket\n",
    "# import openpyxl\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "from test_MYLLM import CustomLLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "\n",
    "class Spark_LLM(CustomLLM):\n",
    "    # 讯飞星火大模型的自定义 LLM\n",
    "    # URL\n",
    "    url : str = \"wss://spark-api.xf-yun.com/v3.5/chat\"\n",
    "    # APPID\n",
    "    appid : str = None\n",
    "    # APISecret\n",
    "    api_secret : str = None\n",
    "    # Domain\n",
    "    domain :str = \"generalv3.5\"\n",
    "    # max_token\n",
    "    max_tokens : int = 4096\n",
    "\n",
    "    def getText(self, role, content, text = []):\n",
    "        # role 是指定角色，content 是 prompt 内容\n",
    "        jsoncon = {}\n",
    "        jsoncon[\"role\"] = role\n",
    "        jsoncon[\"content\"] = content\n",
    "        text.append(jsoncon)\n",
    "        print(text)\n",
    "        return text\n",
    "\n",
    "    def _call(self, \n",
    "              prompt : str, \n",
    "              stop: Optional[List[str]] = None,\n",
    "              run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "              **kwargs: Any):\n",
    "        if self.api_key == None or self.appid == None or self.api_secret == None:\n",
    "            # 三个 Key 均存在才可以正常调用\n",
    "            print(\"请填入 Key\")\n",
    "            raise ValueError(\"Key 不存在\")\n",
    "        # 将 Prompt 填充到星火格式\n",
    "        question = prompt\n",
    "        print(question)\n",
    "        # 发起请求\n",
    "        try:\n",
    "            response = main(self.appid, self.api_key, self.api_secret, self.url, self.domain, question)\n",
    "            # print(response)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"请求失败\")\n",
    "            return \"请求失败\"\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"Spark\"\n",
    "\n",
    "\n",
    "class Ws_Param(object):\n",
    "    # 初始化\n",
    "    def __init__(self, APPID, APIKey, APISecret, gpt_url):\n",
    "        self.APPID = APPID\n",
    "        self.APIKey = APIKey\n",
    "        self.APISecret = APISecret\n",
    "        self.host = urlparse(gpt_url).netloc\n",
    "        self.path = urlparse(gpt_url).path\n",
    "        self.gpt_url = gpt_url\n",
    "\n",
    "    # 生成url\n",
    "    def create_url(self):\n",
    "        # 生成RFC1123格式的时间戳\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "\n",
    "        # 拼接字符串\n",
    "        signature_origin = \"host: \" + self.host + \"\\n\"\n",
    "        signature_origin += \"date: \" + date + \"\\n\"\n",
    "        signature_origin += \"GET \" + self.path + \" HTTP/1.1\"\n",
    "\n",
    "        # 进行hmac-sha256进行加密\n",
    "        signature_sha = hmac.new(self.APISecret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "\n",
    "        signature_sha_base64 = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "\n",
    "        authorization_origin = f'api_key=\"{self.APIKey}\", algorithm=\"hmac-sha256\", headers=\"host date request-line\", signature=\"{signature_sha_base64}\"'\n",
    "\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "\n",
    "        # 将请求的鉴权参数组合为字典\n",
    "        v = {\n",
    "            \"authorization\": authorization,\n",
    "            \"date\": date,\n",
    "            \"host\": self.host\n",
    "        }\n",
    "        # 拼接鉴权参数，生成url\n",
    "        url = self.gpt_url + '?' + urlencode(v)\n",
    "        # 此处打印出建立连接时候的url,参考本demo的时候可取消上方打印的注释，比对相同参数时生成的url与自己代码生成的url是否一致\n",
    "        return url\n",
    "\n",
    "\n",
    "# 收到websocket错误的处理\n",
    "def on_error(ws, error):\n",
    "    print(\"### error:\", error)\n",
    "\n",
    "\n",
    "# 收到websocket关闭的处理\n",
    "def on_close(ws):\n",
    "    print(\"### closed ###\")\n",
    "\n",
    "\n",
    "# 收到websocket连接建立的处理\n",
    "def on_open(ws):\n",
    "    thread.start_new_thread(run, (ws,))\n",
    "\n",
    "\n",
    "def run(ws, *args):\n",
    "    data = json.dumps(gen_params(appid=ws.appid, query=ws.query, domain=ws.domain))\n",
    "    ws.send(data)\n",
    "\n",
    "\n",
    "\n",
    "def gen_params(appid, query, domain):\n",
    "    \"\"\"\n",
    "    通过appid和用户的提问来生成请参数\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"header\": {\n",
    "            \"app_id\": appid,\n",
    "            \"uid\": \"1234\",           \n",
    "            # \"patch_id\": []    #接入微调模型，对应服务发布后的resourceid          \n",
    "        },\n",
    "        \"parameter\": {\n",
    "            \"chat\": {\n",
    "                \"domain\": domain,\n",
    "                \"temperature\": 0.5,\n",
    "                \"max_tokens\": 4096,\n",
    "                \"auditing\": \"default\",\n",
    "            }\n",
    "        },\n",
    "        \"payload\": {\n",
    "            \"message\": {\n",
    "                \"text\": [{\"role\": \"user\", \"content\": query}]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def main(appid, api_secret, api_key, gpt_url, domain, query):\n",
    "    output_queue = queue.Queue()\n",
    "    wsParam = Ws_Param(appid, api_key, api_secret, gpt_url)\n",
    "    websocket.enableTrace(False)\n",
    "    wsUrl = wsParam.create_url()\n",
    "    # 收到websocket消息的处理\n",
    "    def on_message(ws, message):\n",
    "        # print(message)\n",
    "        data = json.loads(message)\n",
    "        code = data['header']['code']\n",
    "        if code != 0:\n",
    "            print(f'请求错误: {code}, {data}')\n",
    "            ws.close()\n",
    "        else:\n",
    "            choices = data[\"payload\"][\"choices\"]\n",
    "            status = choices[\"status\"]\n",
    "            content = choices[\"text\"][0][\"content\"]\n",
    "            #print(content,end='')\n",
    "            output_queue.put(content)\n",
    "            if status == 2:\n",
    "                print(\"#### 关闭会话\")\n",
    "                ws.close()\n",
    "    ws = websocket.WebSocketApp(wsUrl, on_message=on_message, on_error=on_error, on_close=on_close, on_open=on_open)\n",
    "    ws.appid = appid\n",
    "    ws.query = query\n",
    "    ws.domain = domain\n",
    "    ws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\n",
    "    return ''.join([output_queue.get() for _ in range(output_queue.qsize())])\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "apiid = os.getenv(\"SPARK_APPID\")\n",
    "api_key = os.getenv(\"SPARK_API_KEY\")\n",
    "api_secret = os.getenv(\"SPARK_API_SECRET\")\n",
    "llm=Spark_LLM(appid=apiid, api_key=api_key, api_secret=api_secret)\n",
    "llm.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标题：秋日私语\n",
      "\n",
      "秋风轻抚，枫叶如火。我在林间小径漫步，思绪飘渺。落叶铺就金黄地毯，每一步都踏出沙沙的旋律。树梢低语，仿佛在诉说着季节的秘密。我闭上眼睛，让心灵与自然交融，感受那份宁静与和谐。这一刻，我仿佛听见了秋天的私语。#### 关闭会话\n",
      "### error: on_close() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import _thread as thread\n",
    "import os\n",
    "import time\n",
    "import base64\n",
    "\n",
    "import base64\n",
    "import datetime\n",
    "import hashlib\n",
    "import hmac\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import ssl\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from urllib.parse import urlencode\n",
    "from wsgiref.handlers import format_date_time\n",
    "\n",
    "import websocket\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "\n",
    "class Ws_Param(object):\n",
    "    # 初始化\n",
    "    def __init__(self, APPID, APIKey, APISecret, gpt_url):\n",
    "        self.APPID = APPID\n",
    "        self.APIKey = APIKey\n",
    "        self.APISecret = APISecret\n",
    "        self.host = urlparse(gpt_url).netloc\n",
    "        self.path = urlparse(gpt_url).path\n",
    "        self.gpt_url = gpt_url\n",
    "\n",
    "    # 生成url\n",
    "    def create_url(self):\n",
    "        # 生成RFC1123格式的时间戳\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "\n",
    "        # 拼接字符串\n",
    "        signature_origin = \"host: \" + self.host + \"\\n\"\n",
    "        signature_origin += \"date: \" + date + \"\\n\"\n",
    "        signature_origin += \"GET \" + self.path + \" HTTP/1.1\"\n",
    "\n",
    "        # 进行hmac-sha256进行加密\n",
    "        signature_sha = hmac.new(self.APISecret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "\n",
    "        signature_sha_base64 = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "\n",
    "        authorization_origin = f'api_key=\"{self.APIKey}\", algorithm=\"hmac-sha256\", headers=\"host date request-line\", signature=\"{signature_sha_base64}\"'\n",
    "\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "\n",
    "        # 将请求的鉴权参数组合为字典\n",
    "        v = {\n",
    "            \"authorization\": authorization,\n",
    "            \"date\": date,\n",
    "            \"host\": self.host\n",
    "        }\n",
    "        # 拼接鉴权参数，生成url\n",
    "        url = self.gpt_url + '?' + urlencode(v)\n",
    "        # 此处打印出建立连接时候的url,参考本demo的时候可取消上方打印的注释，比对相同参数时生成的url与自己代码生成的url是否一致\n",
    "        return url\n",
    "\n",
    "\n",
    "# 收到websocket错误的处理\n",
    "def on_error(ws, error):\n",
    "    print(\"### error:\", error)\n",
    "\n",
    "\n",
    "# 收到websocket关闭的处理\n",
    "def on_close(ws):\n",
    "    print(\"### closed ###\")\n",
    "\n",
    "\n",
    "# 收到websocket连接建立的处理\n",
    "def on_open(ws):\n",
    "    thread.start_new_thread(run, (ws,))\n",
    "\n",
    "\n",
    "def run(ws, *args):\n",
    "    data = json.dumps(gen_params(appid=ws.appid, query=ws.query, domain=ws.domain))\n",
    "    ws.send(data)\n",
    "\n",
    "\n",
    "# 收到websocket消息的处理\n",
    "def on_message(ws, message):\n",
    "    # print(message)\n",
    "    data = json.loads(message)\n",
    "    code = data['header']['code']\n",
    "    if code != 0:\n",
    "        print(f'请求错误: {code}, {data}')\n",
    "        ws.close()\n",
    "    else:\n",
    "        choices = data[\"payload\"][\"choices\"]\n",
    "        status = choices[\"status\"]\n",
    "        content = choices[\"text\"][0][\"content\"]\n",
    "        print(content,end='')\n",
    "        if status == 2:\n",
    "            print(\"#### 关闭会话\")\n",
    "            ws.close()\n",
    "\n",
    "\n",
    "def gen_params(appid, query, domain):\n",
    "    \"\"\"\n",
    "    通过appid和用户的提问来生成请参数\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"header\": {\n",
    "            \"app_id\": appid,\n",
    "            \"uid\": \"1234\",           \n",
    "            # \"patch_id\": []    #接入微调模型，对应服务发布后的resourceid          \n",
    "        },\n",
    "        \"parameter\": {\n",
    "            \"chat\": {\n",
    "                \"domain\": domain,\n",
    "                \"temperature\": 0.5,\n",
    "                \"max_tokens\": 4096,\n",
    "                \"auditing\": \"default\",\n",
    "            }\n",
    "        },\n",
    "        \"payload\": {\n",
    "            \"message\": {\n",
    "                \"text\": [{\"role\": \"user\", \"content\": query}]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def main(appid, api_secret, api_key, gpt_url, domain, query):\n",
    "    wsParam = Ws_Param(appid, api_key, api_secret, gpt_url)\n",
    "    websocket.enableTrace(False)\n",
    "    wsUrl = wsParam.create_url()\n",
    "\n",
    "    ws = websocket.WebSocketApp(wsUrl, on_message=on_message, on_error=on_error, on_close=on_close, on_open=on_open)\n",
    "    ws.appid = appid\n",
    "    ws.query = query\n",
    "    ws.domain = domain\n",
    "    ws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    import os\n",
    "    apiid = os.getenv(\"SPARK_APPID\")\n",
    "    api_key = os.getenv(\"SPARK_API_KEY\")\n",
    "    api_secret = os.getenv(\"SPARK_API_SECRET\")\n",
    "    main(\n",
    "        appid=apiid,\n",
    "        api_secret=api_secret,\n",
    "        api_key=api_key,\n",
    "        #appid、api_secret、api_key三个服务认证信息请前往开放平台控制台查看（https://console.xfyun.cn/services/bm35）\n",
    "        gpt_url=\"wss://spark-api.xf-yun.com/v3.5/chat\",\n",
    "        # Spark_url = \"ws://spark-api.xf-yun.com/v3.1/chat\"  # v3.0环境的地址\n",
    "        # Spark_url = \"ws://spark-api.xf-yun.com/v2.1/chat\"  # v2.0环境的地址\n",
    "        # Spark_url = \"ws://spark-api.xf-yun.com/v1.1/chat\"  # v1.5环境的地址\n",
    "        domain=\"generalv3.5\",\n",
    "        # domain = \"generalv3\"    # v3.0版本\n",
    "        # domain = \"generalv2\"    # v2.0版本\n",
    "        # domain = \"general\"    # v2.0版本\n",
    "        query=\"给我写一篇100字的作文\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'您好，我是科大讯飞研发的认知智能大模型，我的名字叫讯飞星火认知大模型。我可以和人类进行自然交流，解答问题，高效完成各领域认知智能需求。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Mapping, Optional, Dict, Union, Tuple\n",
    "from pydantic import Field\n",
    "from test_MYLLM import CustomLLM\n",
    "import json\n",
    "import requests\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "import _thread as thread\n",
    "import base64\n",
    "import datetime\n",
    "import hashlib\n",
    "import hmac\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import ssl\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from urllib.parse import urlencode\n",
    "from wsgiref.handlers import format_date_time\n",
    "import websocket  # 使用websocket_client\n",
    "import queue\n",
    "\n",
    "class Spark_LLM(CustomLLM):\n",
    "    # 讯飞星火大模型的自定义 LLM\n",
    "    # URL\n",
    "    url : str = \"wss://spark-api.xf-yun.com/v3.5/chat\"\n",
    "    # APPID\n",
    "    appid : str = None\n",
    "    # APISecret\n",
    "    api_secret : str = None\n",
    "    # Domain\n",
    "    domain :str = \"generalv3.5\"\n",
    "    # max_token\n",
    "    max_tokens : int = 4096\n",
    "\n",
    "    def getText(self, role, content, text = []):\n",
    "        # role 是指定角色，content 是 prompt 内容\n",
    "        jsoncon = {}\n",
    "        jsoncon[\"role\"] = role\n",
    "        jsoncon[\"content\"] = content\n",
    "        text.append(jsoncon)\n",
    "        return text\n",
    "\n",
    "    def _call(self, prompt : str, stop: Optional[List[str]] = None,\n",
    "                run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "                **kwargs: Any):\n",
    "        if self.api_key == None or self.appid == None or self.api_secret == None:\n",
    "            # 三个 Key 均存在才可以正常调用\n",
    "            print(\"请填入 Key\")\n",
    "            raise ValueError(\"Key 不存在\")\n",
    "        # 将 Prompt 填充到星火格式\n",
    "        question = self.getText(\"user\", prompt)\n",
    "        # 发起请求\n",
    "        try:\n",
    "            response = spark_main(self.appid,self.api_key,self.api_secret,self.url,self.domain,question, self.temperature, self.max_tokens)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"请求失败\")\n",
    "            return \"请求失败\"\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"Spark\"\n",
    "\n",
    "class Ws_Param(object):\n",
    "    # 初始化\n",
    "    def __init__(self, APPID, APIKey, APISecret, Spark_url):\n",
    "        self.APPID = APPID\n",
    "        self.APIKey = APIKey\n",
    "        self.APISecret = APISecret\n",
    "        self.host = urlparse(Spark_url).netloc\n",
    "        self.path = urlparse(Spark_url).path\n",
    "        self.Spark_url = Spark_url\n",
    "        # 自定义\n",
    "        self.temperature = 0\n",
    "        self.max_tokens = 2048\n",
    "\n",
    "    # 生成url\n",
    "    def create_url(self):\n",
    "        # 生成RFC1123格式的时间戳\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "\n",
    "        # 拼接字符串\n",
    "        signature_origin = \"host: \" + self.host + \"\\n\"\n",
    "        signature_origin += \"date: \" + date + \"\\n\"\n",
    "        signature_origin += \"GET \" + self.path + \" HTTP/1.1\"\n",
    "\n",
    "        # 进行hmac-sha256进行加密\n",
    "        signature_sha = hmac.new(self.APISecret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "\n",
    "        signature_sha_base64 = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "\n",
    "        authorization_origin = f'api_key=\"{self.APIKey}\", algorithm=\"hmac-sha256\", headers=\"host date request-line\", signature=\"{signature_sha_base64}\"'\n",
    "\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "\n",
    "        # 将请求的鉴权参数组合为字典\n",
    "        v = {\n",
    "            \"authorization\": authorization,\n",
    "            \"date\": date,\n",
    "            \"host\": self.host\n",
    "        }\n",
    "        # 拼接鉴权参数，生成url\n",
    "        url = self.Spark_url + '?' + urlencode(v)\n",
    "        # 此处打印出建立连接时候的url,参考本demo的时候可取消上方打印的注释，比对相同参数时生成的url与自己代码生成的url是否一致\n",
    "        return url\n",
    "\n",
    "\n",
    "# 收到websocket错误的处理\n",
    "def on_error(ws, error):\n",
    "    print(\"### error:\", error)\n",
    "\n",
    "\n",
    "# 收到websocket关闭的处理\n",
    "def on_close(ws,one,two):\n",
    "    print(\" \")\n",
    "\n",
    "\n",
    "# 收到websocket连接建立的处理\n",
    "def on_open(ws):\n",
    "    thread.start_new_thread(run, (ws,))\n",
    "\n",
    "\n",
    "def run(ws, *args):\n",
    "    data = json.dumps(gen_params(appid=ws.appid, domain= ws.domain,question=ws.question, temperature = ws.temperature, max_tokens = ws.max_tokens))\n",
    "    ws.send(data)\n",
    "\n",
    "\n",
    "# 收到websocket消息的处理\n",
    "def on_message(ws, message):\n",
    "    # print(message)\n",
    "    data = json.loads(message)\n",
    "    code = data['header']['code']\n",
    "    if code != 0:\n",
    "        print(f'请求错误: {code}, {data}')\n",
    "        ws.close()\n",
    "    else:\n",
    "        choices = data[\"payload\"][\"choices\"]\n",
    "        status = choices[\"status\"]\n",
    "        content = choices[\"text\"][0][\"content\"]\n",
    "        print(content,end =\"\")\n",
    "        global answer\n",
    "        answer += content\n",
    "        # print(1)\n",
    "        if status == 2:\n",
    "            ws.close()\n",
    "\n",
    "\n",
    "def gen_params(appid, domain,question, temperature, max_tokens):\n",
    "    \"\"\"\n",
    "    通过appid和用户的提问来生成请参数\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"header\": {\n",
    "            \"app_id\": appid,\n",
    "            \"uid\": \"1234\"\n",
    "        },\n",
    "        \"parameter\": {\n",
    "            \"chat\": {\n",
    "                \"domain\": domain,\n",
    "                \"random_threshold\": 0.5,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\" : temperature,\n",
    "                \"auditing\": \"default\"\n",
    "            }\n",
    "        },\n",
    "        \"payload\": {\n",
    "            \"message\": {\n",
    "                \"text\": question\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def spark_main(appid, api_key, api_secret, Spark_url,domain, question, temperature, max_tokens):\n",
    "    # print(\"星火:\")\n",
    "    output_queue = queue.Queue()\n",
    "    def on_message(ws, message):\n",
    "        data = json.loads(message)\n",
    "        code = data['header']['code']\n",
    "        if code != 0:\n",
    "            print(f'请求错误: {code}, {data}')\n",
    "            ws.close()\n",
    "        else:\n",
    "            choices = data[\"payload\"][\"choices\"]\n",
    "            status = choices[\"status\"]\n",
    "            content = choices[\"text\"][0][\"content\"]\n",
    "            # print(content, end='')\n",
    "            # 将输出值放入队列\n",
    "            output_queue.put(content)\n",
    "            if status == 2: \n",
    "                ws.close()\n",
    "\n",
    "    wsParam = Ws_Param(appid, api_key, api_secret, Spark_url)\n",
    "    websocket.enableTrace(False)\n",
    "    wsUrl = wsParam.create_url()\n",
    "    ws = websocket.WebSocketApp(wsUrl, on_message=on_message, on_error=on_error, on_close=on_close, on_open=on_open)\n",
    "    ws.appid = appid\n",
    "    ws.question = question\n",
    "    ws.domain = domain\n",
    "    ws.temperature = temperature\n",
    "    ws.max_tokens = max_tokens\n",
    "    ws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\n",
    "    return ''.join([output_queue.get() for _ in range(output_queue.qsize())])\n",
    "\n",
    "import os\n",
    "apiid = os.getenv(\"SPARK_APPID\")\n",
    "api_key = os.getenv(\"SPARK_API_KEY\")\n",
    "api_secret = os.getenv(\"SPARK_API_SECRET\")\n",
    "llm=Spark_LLM(appid=apiid, api_key=api_key, api_secret=api_secret)\n",
    "llm.invoke(\"你好, 你是谁？\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_queue.qsize() = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Mapping, Optional, Dict, Union, Tuple\n",
    "from pydantic import Field\n",
    "from test_MYLLM import CustomLLM\n",
    "import json\n",
    "import requests\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "import _thread as thread\n",
    "import base64\n",
    "import datetime\n",
    "import hashlib\n",
    "import hmac\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import ssl\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from urllib.parse import urlencode\n",
    "from wsgiref.handlers import format_date_time\n",
    "import websocket  # 使用websocket_client\n",
    "import queue\n",
    "\n",
    "class Spark_LLM(CustomLLM):\n",
    "    # 讯飞星火大模型的自定义 LLM\n",
    "    # URL\n",
    "    url : str = \"wss://spark-api.xf-yun.com/v3.1/chat\"\n",
    "    # APPID\n",
    "    appid : str = None\n",
    "    # APISecret\n",
    "    api_secret : str = None\n",
    "    # Domain\n",
    "    domain :str = \"generalv3\"\n",
    "    # max_token\n",
    "    max_tokens : int = 4096\n",
    "\n",
    "    def getText(self, role, content, text = []):\n",
    "        # role 是指定角色，content 是 prompt 内容\n",
    "        jsoncon = {}\n",
    "        jsoncon[\"role\"] = role\n",
    "        jsoncon[\"content\"] = content\n",
    "        text.append(jsoncon)\n",
    "        return text\n",
    "\n",
    "    def _call(self, prompt : str, stop: Optional[List[str]] = None,\n",
    "                run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "                **kwargs: Any):\n",
    "        if self.api_key == None or self.appid == None or self.api_secret == None:\n",
    "            # 三个 Key 均存在才可以正常调用\n",
    "            print(\"请填入 Key\")\n",
    "            raise ValueError(\"Key 不存在\")\n",
    "        # 将 Prompt 填充到星火格式\n",
    "        question = self.getText(\"user\", prompt)\n",
    "        # 发起请求\n",
    "        try:\n",
    "            response = spark_main(self.appid,self.api_key,self.api_secret,self.url,self.domain,question, self.temperature, self.max_tokens)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"请求失败\")\n",
    "            return \"请求失败\"\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"Spark\"\n",
    "\n",
    "class Ws_Param(object):\n",
    "    # 初始化\n",
    "    def __init__(self, APPID, APIKey, APISecret, Spark_url):\n",
    "        self.APPID = APPID\n",
    "        self.APIKey = APIKey\n",
    "        self.APISecret = APISecret\n",
    "        self.host = urlparse(Spark_url).netloc\n",
    "        self.path = urlparse(Spark_url).path\n",
    "        self.Spark_url = Spark_url\n",
    "        # 自定义\n",
    "        self.temperature = 0\n",
    "        self.max_tokens = 2048\n",
    "\n",
    "    # 生成url\n",
    "    def create_url(self):\n",
    "        # 生成RFC1123格式的时间戳\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "\n",
    "        # 拼接字符串\n",
    "        signature_origin = \"host: \" + self.host + \"\\n\"\n",
    "        signature_origin += \"date: \" + date + \"\\n\"\n",
    "        signature_origin += \"GET \" + self.path + \" HTTP/1.1\"\n",
    "\n",
    "        # 进行hmac-sha256进行加密\n",
    "        signature_sha = hmac.new(self.APISecret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "\n",
    "        signature_sha_base64 = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "\n",
    "        authorization_origin = f'api_key=\"{self.APIKey}\", algorithm=\"hmac-sha256\", headers=\"host date request-line\", signature=\"{signature_sha_base64}\"'\n",
    "\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "\n",
    "        # 将请求的鉴权参数组合为字典\n",
    "        v = {\n",
    "            \"authorization\": authorization,\n",
    "            \"date\": date,\n",
    "            \"host\": self.host\n",
    "        }\n",
    "        # 拼接鉴权参数，生成url\n",
    "        url = self.Spark_url + '?' + urlencode(v)\n",
    "        # 此处打印出建立连接时候的url,参考本demo的时候可取消上方打印的注释，比对相同参数时生成的url与自己代码生成的url是否一致\n",
    "        return url\n",
    "\n",
    "\n",
    "# 收到websocket错误的处理\n",
    "def on_error(ws, error):\n",
    "    print(\"### error:\", error)\n",
    "\n",
    "\n",
    "# 收到websocket关闭的处理\n",
    "def on_close(ws,one,two):\n",
    "    pass\n",
    "\n",
    "\n",
    "# 收到websocket连接建立的处理\n",
    "def on_open(ws):\n",
    "    thread.start_new_thread(run, (ws,))\n",
    "\n",
    "\n",
    "def run(ws, *args):\n",
    "    data = json.dumps(gen_params(appid=ws.appid, domain= ws.domain,question=ws.question, temperature = ws.temperature, max_tokens = ws.max_tokens))\n",
    "    ws.send(data)\n",
    "\n",
    "\n",
    "# # 收到websocket消息的处理\n",
    "# def on_message(ws, message):\n",
    "#     # print(message)\n",
    "#     data = json.loads(message)\n",
    "#     code = data['header']['code']\n",
    "#     if code != 0:\n",
    "#         print(f'请求错误: {code}, {data}')\n",
    "#         ws.close()\n",
    "#     else:\n",
    "#         choices = data[\"payload\"][\"choices\"]\n",
    "#         status = choices[\"status\"]\n",
    "#         content = choices[\"text\"][0][\"content\"]\n",
    "#         print(content,end =\"\")\n",
    "#         global answer\n",
    "#         answer += content\n",
    "#         # print(1)\n",
    "#         if status == 2:\n",
    "#             ws.close()\n",
    "\n",
    "\n",
    "def gen_params(appid, domain,question, temperature, max_tokens):\n",
    "    \"\"\"\n",
    "    通过appid和用户的提问来生成请参数\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"header\": {\n",
    "            \"app_id\": appid,\n",
    "            \"uid\": \"1234\"\n",
    "        },\n",
    "        \"parameter\": {\n",
    "            \"chat\": {\n",
    "                \"domain\": domain,\n",
    "                \"random_threshold\": 0.5,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\" : temperature,\n",
    "                \"auditing\": \"default\"\n",
    "            }\n",
    "        },\n",
    "        \"payload\": {\n",
    "            \"message\": {\n",
    "                \"text\": question\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def spark_main(appid, api_key, api_secret, Spark_url,domain, question, temperature, max_tokens):\n",
    "    # print(\"星火:\")\n",
    "    output_queue = queue.Queue()\n",
    "    def on_message(ws, message):\n",
    "        data = json.loads(message)\n",
    "        code = data['header']['code']\n",
    "        if code != 0:\n",
    "            print(f'请求错误: {code}, {data}')\n",
    "            ws.close()\n",
    "        else:\n",
    "            choices = data[\"payload\"][\"choices\"]\n",
    "            status = choices[\"status\"]\n",
    "            content = choices[\"text\"][0][\"content\"].strip()\n",
    "\n",
    "            # content = '\\n'.join(line for line in content.splitlines() if line.strip())\n",
    "            if content:\n",
    "                # print(content, end='')\n",
    "                output_queue.put(content)\n",
    "            if status == 2: \n",
    "                # print(f\"status == 2, output_queue = {output_queue.qsize()}\")\n",
    "                ws.close()\n",
    "\n",
    "    wsParam = Ws_Param(appid, api_key, api_secret, Spark_url)\n",
    "    websocket.enableTrace(False)\n",
    "    wsUrl = wsParam.create_url()\n",
    "    ws = websocket.WebSocketApp(wsUrl, on_message=on_message, on_error=on_error, on_close=on_close, on_open=on_open)\n",
    "    ws.appid = appid\n",
    "    ws.question = question\n",
    "    ws.domain = domain\n",
    "    ws.temperature = temperature\n",
    "    ws.max_tokens = max_tokens\n",
    "    print(f\"output_queue.qsize() = {output_queue.qsize()}\")\n",
    "    # print(f\"wsUrl = {wsUrl}\")\n",
    "    ws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\n",
    "    \n",
    "    # print([output_queue.get() for _ in range(output_queue.qsize())])\n",
    "    return (''.join([output_queue.get() for _ in range(output_queue.qsize())]).strip())\n",
    "\n",
    "import os\n",
    "apiid = os.getenv(\"SPARK_APPID\")\n",
    "api_key = os.getenv(\"SPARK_API_KEY\")\n",
    "api_secret = os.getenv(\"SPARK_API_SECRET\")\n",
    "llm=Spark_LLM(appid=apiid, api_key=api_key, api_secret=api_secret)\n",
    "print(llm.invoke(\"你好\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MChat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
